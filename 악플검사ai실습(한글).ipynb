{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kUnVFIJUJ6yKvrrpymI3awBULMZ3dm4h",
      "authorship_tag": "ABX9TyORYz8J7Uc/wKi1XzrjhXjO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-2ZyaFHEUTd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 파일 읽어서 컬럼에 제목 추가\n",
        "raw = pd.read_table('drive/MyDrive/aipython/shopping.txt', names=['rating','review'])\n",
        "#print(raw)\n",
        "\n",
        "# 평점으로 리뷰가 악플인지 선플인지 구분\n",
        "raw['label'] = np.where( raw['rating'] > 3, 1, 0 )\n",
        "print(raw)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 데이터 전처리\n",
        "# 정규식으로 특문 제거\n",
        "raw['review'] = raw['review'].str.replace('[^ㄱ-ㅎ ㅏ-ㅣ 가-힣0-9 ]','')\n",
        "''' print(raw.isnull().sum()) '''\n",
        "print(raw)\n",
        "\n",
        "# 중복 데이터 제거\n",
        "raw.drop_duplicates( subset=['review'], inplace=True )\n",
        "print(raw)\n",
        "\n",
        "# bag of words\n",
        "유니크문자 = raw['review'].tolist()\n",
        "유니크문자 = ''.join(유니크문자)\n",
        "유니크문자 = list(set(유니크문자))\n",
        "유니크문자.sort()\n",
        "print(유니크문자[0:100])"
      ],
      "metadata": {
        "id": "Zl0o3TMbHQWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자들을 정수로 바꾸기\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# OOV는 새롭게 생긴 단어를 뭘로 치환할건지 설정 : 없는 단어일때 <OOV>로 치환\n",
        "tokenizer = Tokenizer(char_level=True, oov_token = '<OOV>')  # true일때 글자단위 정수변환, false일때 단어단위 정수변환\n",
        "\n",
        "문자리스트 = raw['review'].tolist()\n",
        "tokenizer.fit_on_texts(문자리스트)\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(문자리스트[0:10])\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(문자리스트)\n",
        "print(train_seq[0:10])\n",
        "\n",
        "# 정답 데이터\n",
        "Y = raw['label'].tolist()"
      ],
      "metadata": {
        "id": "1r_Ihar2MHjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 글자수 똑같이 맞추기 (그래야 모델에 삽입가능)\n",
        "#print(raw.describe())  # 데이터의 통계\n",
        "\n",
        "raw['length'] = raw['review'].str.len()\n",
        "\n",
        "print(raw.head())\n",
        "print(raw.describe())\n",
        "\n",
        "raw['length'][raw['length'] < 110].count()"
      ],
      "metadata": {
        "id": "1bYJT3PJdLp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(train_seq, maxlen=100)  #maxlen보다 작은경우 0으로 채우고, 길다면 maxlen길이만큼 자름\n",
        "\n",
        "#train/test/val 쪼개기\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainX, valX, trainY, valY = train_test_split(X,Y,test_size=0.2, random_state=42) # seed 42\n",
        "\n",
        "print(len(trainX))\n",
        "print(len(valX))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ub_HatFugG4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(len(word_index)+1,16),  # one hot 인코딩 대신 사용 가능. 벡터로 변환\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "Eow2HMW6hVpv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}